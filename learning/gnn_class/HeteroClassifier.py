import dgl.data
import torch.nn as nn
import dgl.nn.pytorch as dglnn
import torch.nn.functional as F

class RGCN(nn.Module):    
    def __init__(self, in_feats, hid_feats, out_feats, rel_names, dropout):
        super().__init__()

        self.conv1 = dglnn.HeteroGraphConv({
            rel: dglnn.GraphConv(in_feats, hid_feats)
            for rel in rel_names}, aggregate='sum')
        self.conv2 = dglnn.HeteroGraphConv({
            rel: dglnn.GraphConv(hid_feats, out_feats)
            for rel in rel_names}, aggregate='sum')
        self.dropout = nn.Dropout(dropout)  # 드롭아웃 추가

    def forward(self, graph, inputs):
        # inputs is features of nodes
        h = self.conv1(graph, inputs)
        h = {k: F.relu(v) for k, v in h.items()}
        h = {k: self.dropout(v) for k, v in h.items()}  # 각 노드 유형별로 드롭아웃 적용
        h = self.conv2(graph, h)
        return h

class HeteroClassifier(nn.Module):    
    def __init__(self, in_dim, hidden_dim, n_classes, rel_names):
        super().__init__()

        self.rgcn = RGCN(in_dim, hidden_dim, hidden_dim, rel_names, 0.5)
        self.classify = nn.Linear(hidden_dim, n_classes)
        
    def forward(self, g):
        h = g.ndata['feat']
        # h = {k: v.to('cuda') for k, v in h.items()}
        h = self.rgcn(g, h)
        with g.local_scope():
            g.ndata['h'] = h
            # Calculate graph representation by average readout.
            hg = 0
            for ntype in g.ntypes:
                if ntype == "Function":
                    continue
                hg = hg + dgl.mean_nodes(g, 'h', ntype=ntype)
            return F.softmax(self.classify(hg), dim=1)